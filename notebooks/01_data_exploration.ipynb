{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c550e5bf",
   "metadata": {},
   "source": [
    "# Part 1: Data Pipeline & Historical Analysis\n",
    "**Project:** ForgeFlow Manufacturing Analytics\n",
    "**Author:** Jaylen Hester\n",
    "\n",
    "### üéØ Objective\n",
    "To engineer an end-to-end data pipeline that simulates a manufacturing environment, integrates it with real-world quality control and sales data, and performs root-cause analysis on historical defects.\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "1.  **Supply Side (Simulation):** Custom Python package (`forgeflow`) generates 365 days of production logs.\n",
    "2.  **Telemetry Layer (Ingestion):** Integration of UCI SECOM sensor data to simulate machine states.\n",
    "3.  **Demand Side (Real World):** Integration of Olist E-Commerce data to track downstream customer sentiment.\n",
    "4.  **Analytics Engine:** In-Memory SQLite warehouse for multi-source SQL joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Package loaded: /workspaces/forgeflow-manufacturing-analytics/src/forgeflow/__init__.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. SETUP\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "\n",
    "# Add local src directory to path for package import\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "try:\n",
    "    import forgeflow\n",
    "    from forgeflow import synth, clean, features, io, paths\n",
    "    print(f\"Package loaded: {forgeflow.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error loading forgeflow package: {e}\")\n",
    "\n",
    "# Mapping dictionary to link synthetic products to Olist SKUs\n",
    "PRODUCT_MAPPING = {\n",
    "    \"microwave\": \"1e9e8ef04dbcff4541ed26657ea517e5\",\n",
    "    \"vacuum\": \"3aa071139cb16b67ca9e5dea641aaa2f\",\n",
    "    \"coffee_maker\": \"a62b9723af96d72995a548a67bb184e5\"\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b067c66",
   "metadata": {},
   "source": [
    "## 1. Supply Chain Simulation\n",
    "**Goal:** Generate a synthetic \"Ground Truth\" for manufacturing operations.\n",
    "We utilize the internal `synth` module to create production batches across three distinct plant locations, standardizing the schema for downstream integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13bd660b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating production logs...\n",
      "Generated 3285 records.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>plant</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>defect_rate</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>olist_product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>microwave</td>\n",
       "      <td>212</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>BATCH-00000</td>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>157</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>BATCH-00001</td>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>coffee_maker</td>\n",
       "      <td>191</td>\n",
       "      <td>0.024916</td>\n",
       "      <td>BATCH-00002</td>\n",
       "      <td>a62b9723af96d72995a548a67bb184e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>manaus</td>\n",
       "      <td>microwave</td>\n",
       "      <td>198</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>BATCH-00003</td>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>manaus</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>155</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>BATCH-00004</td>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     plant       product  units  defect_rate     batch_id  \\\n",
       "0  2024-11-25  campinas     microwave    212     0.033752  BATCH-00000   \n",
       "1  2024-11-25  campinas        vacuum    157     0.013489  BATCH-00001   \n",
       "2  2024-11-25  campinas  coffee_maker    191     0.024916  BATCH-00002   \n",
       "3  2024-11-25    manaus     microwave    198     0.033889  BATCH-00003   \n",
       "4  2024-11-25    manaus        vacuum    155     0.022338  BATCH-00004   \n",
       "\n",
       "                   olist_product_id  \n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5  \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f  \n",
       "2  a62b9723af96d72995a548a67bb184e5  \n",
       "3  1e9e8ef04dbcff4541ed26657ea517e5  \n",
       "4  3aa071139cb16b67ca9e5dea641aaa2f  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 1. Synthetic Data Generation\n",
    "# Simulates 365 days of production logs across 3 distinct plants using the internal `synth` module.\n",
    "\n",
    "# %%\n",
    "print(\"Generating production logs...\")\n",
    "\n",
    "# Configure and run simulation\n",
    "cfg = synth.SynthConfig(n_days=365, seed=42)\n",
    "df_production = synth.make_production(cfg)\n",
    "\n",
    "# Standardize column names\n",
    "df_production = clean.standardize_columns(df_production)\n",
    "\n",
    "# Generate unique Batch IDs for tracking\n",
    "df_production[\"batch_id\"] = [f\"BATCH-{i:05d}\" for i in range(len(df_production))]\n",
    "\n",
    "# Map internal product names to external Olist IDs\n",
    "df_production[\"olist_product_id\"] = df_production[\"product\"].map(PRODUCT_MAPPING)\n",
    "\n",
    "print(f\"Generated {len(df_production)} records.\")\n",
    "df_production.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d8fba3",
   "metadata": {},
   "source": [
    "## 2. Data Ingestion & Integration\n",
    "**Objective:** Ingest real-world datasets and merge them with synthetic production logs.\n",
    "\n",
    "**Data Sources:**\n",
    "* **Olist (E-Commerce):** Orders, Items, and Reviews (CSV).\n",
    "* **SECOM (Sensors):** UCI Semiconductor Manufacturing dataset (CSV).\n",
    "\n",
    "**Transformations:**\n",
    "* **Column Selection:** Extracts specific sensor columns (Pressure, Temp, Vibration, Amperage) from SECOM, explicitly discarding the raw timestamp (Column 0).\n",
    "* **Telemetry Mapping:** Randomly maps sensor readings to specific production batches to simulate incomplete telemetry coverage (Left Join)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f75785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading external datasets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "External data loaded successfully.\n",
      "Linking sensor telemetry to production batches...\n",
      "Master Integration Complete. Final Shape: (3615, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>plant</th>\n",
       "      <th>product</th>\n",
       "      <th>units</th>\n",
       "      <th>defect_rate</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>olist_product_id</th>\n",
       "      <th>sensor_pressure</th>\n",
       "      <th>sensor_temp</th>\n",
       "      <th>sensor_vibration</th>\n",
       "      <th>sensor_amp</th>\n",
       "      <th>is_defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>microwave</td>\n",
       "      <td>212</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>BATCH-00000</td>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>157</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>BATCH-00001</td>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>2992.52</td>\n",
       "      <td>2470.14</td>\n",
       "      <td>2197.6444</td>\n",
       "      <td>1247.0334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>campinas</td>\n",
       "      <td>coffee_maker</td>\n",
       "      <td>191</td>\n",
       "      <td>0.024916</td>\n",
       "      <td>BATCH-00002</td>\n",
       "      <td>a62b9723af96d72995a548a67bb184e5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>manaus</td>\n",
       "      <td>microwave</td>\n",
       "      <td>198</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>BATCH-00003</td>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>3043.77</td>\n",
       "      <td>2588.52</td>\n",
       "      <td>2219.7667</td>\n",
       "      <td>2086.4710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-11-25</td>\n",
       "      <td>manaus</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>155</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>BATCH-00004</td>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>3036.93</td>\n",
       "      <td>2570.13</td>\n",
       "      <td>2230.7555</td>\n",
       "      <td>1281.7862</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     plant       product  units  defect_rate     batch_id  \\\n",
       "0  2024-11-25  campinas     microwave    212     0.033752  BATCH-00000   \n",
       "1  2024-11-25  campinas        vacuum    157     0.013489  BATCH-00001   \n",
       "2  2024-11-25  campinas  coffee_maker    191     0.024916  BATCH-00002   \n",
       "3  2024-11-25    manaus     microwave    198     0.033889  BATCH-00003   \n",
       "4  2024-11-25    manaus        vacuum    155     0.022338  BATCH-00004   \n",
       "\n",
       "                   olist_product_id  sensor_pressure  sensor_temp  \\\n",
       "0  1e9e8ef04dbcff4541ed26657ea517e5              NaN          NaN   \n",
       "1  3aa071139cb16b67ca9e5dea641aaa2f          2992.52      2470.14   \n",
       "2  a62b9723af96d72995a548a67bb184e5              NaN          NaN   \n",
       "3  1e9e8ef04dbcff4541ed26657ea517e5          3043.77      2588.52   \n",
       "4  3aa071139cb16b67ca9e5dea641aaa2f          3036.93      2570.13   \n",
       "\n",
       "   sensor_vibration  sensor_amp  is_defective  \n",
       "0               NaN         NaN             1  \n",
       "1         2197.6444   1247.0334             0  \n",
       "2               NaN         NaN             0  \n",
       "3         2219.7667   2086.4710             1  \n",
       "4         2230.7555   1281.7862             0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %%\n",
    "# 1. LOAD EXTERNAL DATA\n",
    "print(\"Loading external datasets...\")\n",
    "\n",
    "# FIX: Initialize variables to None first so the Linter is happy\n",
    "orders = None\n",
    "items = None\n",
    "reviews = None\n",
    "secom_clean = None \n",
    "\n",
    "try:\n",
    "    # Load Demand Data (Olist)\n",
    "    orders = io.read_raw_csv('olist/olist_orders_dataset.csv')\n",
    "    items = io.read_raw_csv('olist/olist_order_items_dataset.csv')\n",
    "    reviews = io.read_raw_csv('olist/olist_order_reviews_dataset.csv')\n",
    "    \n",
    "    # Load Sensor Data (SECOM)\n",
    "    # NOTE: Column 0 is a timestamp (Year 2008). We exclude it using iloc[:, 1:5]\n",
    "    # to capture only the relevant sensor readings (cols 1-4).\n",
    "    secom = io.read_raw_csv('secom/uci-secom.csv')\n",
    "    secom_clean = secom.iloc[:, 1:5].copy()\n",
    "    secom_clean.columns = ['sensor_pressure', 'sensor_temp', 'sensor_vibration', 'sensor_amp']\n",
    "    \n",
    "    print(\"External data loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading external data: {e}\")\n",
    "\n",
    "# 2. MERGE SENSORS WITH PRODUCTION\n",
    "# We verify data loaded correctly before running the merge logic\n",
    "if secom_clean is not None and df_production is not None:\n",
    "    print(\"Linking sensor telemetry to production batches...\")\n",
    "\n",
    "    # Set seed to ensure reproducible mapping for modeling\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Randomly assign sensor rows to existing Batch IDs\n",
    "    assigned_batches = np.random.choice(df_production['batch_id'], size=len(secom_clean))\n",
    "    secom_clean['batch_id'] = assigned_batches\n",
    "\n",
    "    # Master Merge: Production Logs (Left) + Sensor Data (Right)\n",
    "    # Result: All production batches are kept; those without sensor data will have NaNs.\n",
    "    df_master = df_production.merge(secom_clean, on=\"batch_id\", how=\"left\")\n",
    "\n",
    "    # Feature Engineering: Create binary target for Defect Classification\n",
    "    # Logic: A Defect Rate > 2.5% is classified as a \"Failure\" (1).\n",
    "    df_master['is_defective'] = (df_master['defect_rate'] > 0.025).astype(int)\n",
    "\n",
    "    print(f\"Master Integration Complete. Final Shape: {df_master.shape}\")\n",
    "    display(df_master.head())\n",
    "else:\n",
    "    print(\"‚ùå Critical Error: Data Ingestion failed. Skipping Merge step.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ea045",
   "metadata": {},
   "source": [
    "## 3. Business Intelligence Analysis\n",
    "**Goal:** Execute Root Cause Analysis using SQL.\n",
    "We instantiate an in-memory Data Warehouse to join **Factory Logs** (Supply), **Sensor Telemetry** (Process), and **Customer Reviews** (Demand).\n",
    "\n",
    "**Key Business Question:**\n",
    "> *\"How do upstream factory anomalies (e.g., High Pressure) impact downstream customer satisfaction?\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1f7ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Data Warehouse...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>plant</th>\n",
       "      <th>product</th>\n",
       "      <th>batches_with_sensor_logs</th>\n",
       "      <th>avg_pressure</th>\n",
       "      <th>avg_vibration</th>\n",
       "      <th>defect_pct</th>\n",
       "      <th>avg_stars</th>\n",
       "      <th>review_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recife</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>166</td>\n",
       "      <td>3024.57</td>\n",
       "      <td>2199.55</td>\n",
       "      <td>2.04%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>campinas</td>\n",
       "      <td>microwave</td>\n",
       "      <td>173</td>\n",
       "      <td>3019.06</td>\n",
       "      <td>2196.97</td>\n",
       "      <td>2.97%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>manaus</td>\n",
       "      <td>microwave</td>\n",
       "      <td>175</td>\n",
       "      <td>3016.52</td>\n",
       "      <td>2200.62</td>\n",
       "      <td>3.02%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>campinas</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>182</td>\n",
       "      <td>3013.09</td>\n",
       "      <td>2197.29</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>manaus</td>\n",
       "      <td>vacuum</td>\n",
       "      <td>171</td>\n",
       "      <td>3011.84</td>\n",
       "      <td>2202.92</td>\n",
       "      <td>2.0%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recife</td>\n",
       "      <td>microwave</td>\n",
       "      <td>164</td>\n",
       "      <td>3008.78</td>\n",
       "      <td>2204.04</td>\n",
       "      <td>3.0%</td>\n",
       "      <td>5.0</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      plant    product  batches_with_sensor_logs  avg_pressure  avg_vibration  \\\n",
       "0    recife     vacuum                       166       3024.57        2199.55   \n",
       "1  campinas  microwave                       173       3019.06        2196.97   \n",
       "2    manaus  microwave                       175       3016.52        2200.62   \n",
       "3  campinas     vacuum                       182       3013.09        2197.29   \n",
       "4    manaus     vacuum                       171       3011.84        2202.92   \n",
       "5    recife  microwave                       164       3008.78        2204.04   \n",
       "\n",
       "  defect_pct  avg_stars  review_vol  \n",
       "0      2.04%        5.0         406  \n",
       "1      2.97%        5.0         395  \n",
       "2      3.02%        5.0         398  \n",
       "3       2.0%        5.0         400  \n",
       "4       2.0%        5.0         393  \n",
       "5       3.0%        5.0         392  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## 3. SQL Analysis\n",
    "# Aggregates key performance metrics (pressure, vibration, defect rate, review scores) using an in-memory SQLite database.\n",
    "\n",
    "# %%\n",
    "# Initialize database connection\n",
    "conn = sqlite3.connect(':memory:')\n",
    "\n",
    "# FIX: We only run SQL logic if all necessary DataFrames exist.\n",
    "# This satisfies the Linter (\"reportOptionalMemberAccess\").\n",
    "if (df_production is not None and \n",
    "    secom_clean is not None and \n",
    "    items is not None and \n",
    "    reviews is not None):\n",
    "\n",
    "    print(\"Building Data Warehouse...\")\n",
    "\n",
    "    # Load tables into warehouse\n",
    "    df_production.to_sql('fact_production', conn, index=False, if_exists='replace')\n",
    "    secom_clean.to_sql('fact_sensors', conn, index=False, if_exists='replace')\n",
    "    items.to_sql('dim_items', conn, index=False, if_exists='replace')\n",
    "    reviews.to_sql('dim_reviews', conn, index=False, if_exists='replace')\n",
    "\n",
    "    # Query: The Full \"Magnum Opus\" Analysis\n",
    "    query = \"\"\"\n",
    "    SELECT \n",
    "        -- 1. Segments\n",
    "        p.plant,\n",
    "        p.product,\n",
    "        \n",
    "        -- 2. Factory Telemetry (The \"Why\")\n",
    "        COUNT(s.batch_id) as batches_with_sensor_logs,\n",
    "        ROUND(AVG(s.sensor_pressure), 2) as avg_pressure,\n",
    "        ROUND(AVG(s.sensor_vibration), 2) as avg_vibration,\n",
    "        \n",
    "        -- 3. Production Quality (The \"What\")\n",
    "        ROUND(AVG(p.defect_rate) * 100, 2) || '%' as defect_pct,\n",
    "        \n",
    "        -- 4. Customer Impact (The \"So What\")\n",
    "        ROUND(AVG(r.review_score), 2) as avg_stars,\n",
    "        COUNT(r.review_id) as review_vol\n",
    "\n",
    "    FROM fact_production p\n",
    "\n",
    "    -- Join Sensor Data (Left Join to keep batches even if sensors missed them)\n",
    "    LEFT JOIN fact_sensors s ON p.batch_id = s.batch_id\n",
    "\n",
    "    -- Join Olist Data (Bridge to Real World)\n",
    "    JOIN dim_items i ON p.olist_product_id = i.product_id\n",
    "    JOIN dim_reviews r ON i.order_id = r.order_id\n",
    "\n",
    "    GROUP BY 1, 2\n",
    "    ORDER BY avg_pressure DESC\n",
    "    \"\"\"\n",
    "\n",
    "    df_insight = pd.read_sql(query, conn)\n",
    "    display(df_insight)\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping SQL Analysis: One or more upstream datasets failed to load.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118611f2",
   "metadata": {},
   "source": [
    "## 4. Pipeline Export\n",
    "**Goal:** Serialize processed datasets for the next stages of the project.\n",
    "* **`forgeflow_sql_summary.csv`**: Aggregated KPIs for the Tableau Dashboard (Part 3).\n",
    "* **`forgeflow_modeling_data.csv`**: Granular feature matrix for Machine Learning (Part 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b180eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting processed files...\n",
      "Original Batches: 3615\n",
      "Batches with Sensor Data (Model Ready): 1561\n",
      "Export complete. Ready for Notebook 02_Modeling.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Exporting processed files...\")\n",
    "\n",
    "# 1. Save SQL Summary (For Tableau Dashboard)\n",
    "# This keeps the \"Big Picture\" view\n",
    "io.write_processed_csv(df_insight, \"forgeflow_sql_summary.csv\")\n",
    "\n",
    "# 2. Save Modeling Data (For Machine Learning)\n",
    "# CRITICAL STEP: We drop rows where sensors are missing.\n",
    "# We can't train a \"Sensor Model\" on empty data.\n",
    "df_model_ready = df_master.dropna(subset=['sensor_pressure'])\n",
    "\n",
    "print(f\"Original Batches: {len(df_master)}\")\n",
    "print(f\"Batches with Sensor Data (Model Ready): {len(df_model_ready)}\")\n",
    "\n",
    "io.write_processed_csv(df_model_ready, \"forgeflow_modeling_data.csv\")\n",
    "\n",
    "print(\"Export complete. Ready for Notebook 02_Modeling.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
